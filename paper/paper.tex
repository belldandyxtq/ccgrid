%\documentclass[10pt, conference, compsocconf]{IEEEtran}
\documentclass[10pt, conference, compsocconf]{IEEEtran}
\usepackage{color}
\usepackage{supertabular}
\usepackage{graphicx}
\usepackage{flushend}
\usepackage{cite}
\usepackage{subfigure}
\usepackage{comment}
\usepackage[cmex10]{amsmath}
\usepackage{colortbl}

\definecolor{darkgray}{gray}{0.7}
\definecolor{lightgray}{gray}{0.9}

\bibliographystyle{IEEEtran}

\begin{document}

\newcommand {\xtq}[1] {\begin{color}{red}{[XTQ : #1]}\end{color}}
\newcommand{\kento}[1]{{\color{blue} [Kento: {\it #1}]}}
\newcommand {\xtqmod}[1] {\begin{color}{magenta}{[XTQ MODIFICATION: #1]}\end{color}}

%\newcommand {\xtq}[1] {}
%start title
%\title{Studies of Cloud Based Burst Buffers to Burst Data Intensive Application on
%the Cloud}
\title{Explorations of Cloud-based Burst Buffers for I/O Acceleration}%Data Caching}%Data Intensive
% Applications }

\author{
\IEEEauthorblockN{Tianqi Xu}
	\IEEEauthorblockA{Dept. of Mathematical\\and Computing Sciences\\
		Tokyo Institute of Technology\\
		2-12-1-W8-33, Ohokayama,\\
		Meguro-ku, Tokyo 152-8552 Japan\\
	Email: yo.t.aa@m.titech.ac.jp}
	\and
	\IEEEauthorblockN{Kento Sato}
	\IEEEauthorblockA{Center for Applied Scientific Computing\\
		Lawrence Livermore National Laboratory\\
		Livermore, CA 94551 USA\\
	Email: kento@llnl.gov}
	\and
	\IEEEauthorblockN{Satoshi Matsuoka}
	\IEEEauthorblockA{Global Scientific \\Information and Computing Center\\
		Tokyo Institute of Technology\\
		2-12-1-W8-33, Ohokayama,\\
		Meguro-ku, Tokyo 152-8552 Japan\\
	Email: matsu@is.titech.ac.jp}
}

\maketitle


%start abstract
\begin{abstract}
Cloud computing offers high computational resources, scalability, as well as
ease of access.
%Such cloud environments offer those who have limited local computational
%resources a opportunity to run large scale applications.
Such cloud environments provide the users with virtually unlimited computational
resources to run HPC applications at larger scale than what in-house
systems can provide. 
%Current data intensive large scale applications generate TB
%intermediate data shared among hundreds of compute nodes, so the shared storage
% throughput becomes critical part.
Since large scale data intensive applications typically generate huge amount of
intermediate data, and shared by hundreds and thousands of compute nodes,
data intensive applications require high I/O throughput to shared storage.
%However compare to the throughput in HPC system, the shared storage
%system in cloud environment can only achieve a quite low I/O throughput,
% becoming the performance bottleneck for data intensive applications.
However, current shared storage in cloud environments can not provide
enough I/O throughput for data intensive applications.
The low I/O throughput becomes a performance bottleneck.
%Furthermore, according to normal cloud pay-as-you-go pricing,
%longer execution time means more you should pay.
Furthermore, the prolonged execution time incur more cost to users as the most
of cloud providers employ pay-as-you-go pricing modes.
%In this paper, we propose a cloud based
%burst buffer system as a new tier in cloud storage system to absorb I/O
% request.
To accelerate I/O performance, we propose a cloud-based burst buffer system as a
new tier in cloud storage systems.
%We use several nodes as a burst buffer nodes,
%take advantage of high throughput inside cloud to buffer application I/O data.
The cloud-based burst buffer system uses computing nodes as burst buffer nodes,
and buffers applications' data in the burst buffer nodes. Because throughput
between compute nodes is much higher than shared storage throughput, we can
accelerate I/O performance for data intensive applications.
%We implemented a
%prototype of our proposal architecture, evaluated in Amazon EC2/S3(one of the
% most common public cloud today).
%We shows our system can achieve a significant improvement in I/O throughput for
% shared storage
%in cloud computing through experimental and simulation evaluation.
To explore the effectiveness of cloud-based burst buffers, 
We implement a prototype, and evaluate the system in Amazon
EC2/S3.
The experimental and simulation evaluations show that our prototype system
can achieve up to 1.5 times improvement in the execution time of real applications.
\end{abstract}

%start key word
\begin{IEEEkeywords}
	cloud computing, burst buffer, data intensive applications
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle

%section I
\input{src/introduction.tex}

%section II
\input{src/background.tex}

%section III
%\input{src/architecture.tex}

%section IV
\input{src/implementation.tex}

%section V
%\input{src/modeling.tex}
\input{src/modeling-2.tex}

%section VI
\input{src/evaluation.tex}

%section VII
\input{src/related_work.tex}

%section VIII
\input{src/conclusion.tex}

\section*{Acknowledgement}
This work was performed under the auspices of the U.S. Department of Energy by
Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344.
(LLNL-CONF-663584-DRAFT).
This research was supported by JST, CREST (Research Area: Advanced Core Technologies for
Big Data Integration).
This research made use of Montage, funded by the National Aeronautics and Space Administration's
Earth Science Technology Office, Computation Technologies Project, under
Cooperative Agreement Number NCC5-626 between NASA and the California Institute
of Technology. Montage is maintained by the NASA/IPAC Infrared Science Archive.
\bibliography{src/ref/reference.bib}

\end{document}
